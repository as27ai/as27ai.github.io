<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Who Captures the Profits in the GenAI Stack? | Aaryan Shah</title>
    <meta name="description" content="A concise tour of today‚Äôs GenAI stack‚Äîsilicon to apps‚Äîwhy NVIDIA currently captures the lion‚Äôs share of value, and how shifting stack boundaries will shape the next phase." />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet" />
    <link rel="stylesheet" href="../assets/css/styles.css" />
  </head>
  <body class="blog-post">
    
    <header class="site-header">
      <div class="container header-content">
        <a href="../index.html" class="brand">Aaryan Shah</a>
        <div class="header-right">
        <nav class="site-nav" aria-label="Primary">
          <a href="../index.html#about">About</a>
          <a href="../index.html#blog">Blog</a>
          <a href="../index.html#contact">Contact</a>
          <button class="theme-toggle" type="button" aria-label="Toggle light and dark theme">üåó</button>
        </nav>
        </div>
      </div>
    </header>

    <main>
      <section class="hero" id="post-hero">
        <div class="container">
          <p class="eyebrow">Blog ¬∑ GenAI Strategy</p>
          <h1>Who can capture the most profits from the GenAI Stack today?</h1>
          <p class="lead">
            GenAI is no longer just an innovation - it‚Äôs the foundation for the next wave of tools, business models, and user experiences.
            In this fast shifting AI landscape, one core question prevails: who is best positioned to capture the most profits from this shift?
            OpenAI may have made ChatGPT a verb, but today, it's NVIDIA which stands out. Its dominant role in AI accelerators (mainly their GPUs),
            high margins, and expanding influence across the GenAI stack make it uniquely advantaged
          </p>
        </div>
      </section>

      <section class="about">
        <div class="container about-content">
          <article class="about-text" style="max-width: 900px;">
            <h2>1) The GenAI stack today</h2>
            <p>
              A four-layer view‚Äî<strong>Silicon/AI accelerators</strong>, <strong>Infrastructure/Cloud</strong>,
              <strong>Platform &amp; Models</strong>, and <strong>Applications</strong>‚Äîbest explains how capability turns into value.
              Most of the ongoing cost of an LLM API call sits in compute (GPUs/TPUs), not software OPEX. This puts outsized
              economics at the silicon layer.
            </p>

            <h2>2) How major players position across the stack</h2>
            <ul>
              <li><strong>Google</strong>: Vertically integrated (TPU ‚Üí GCP ‚Üí Gemini ‚Üí Workspace)</li>
              <li><strong>Meta</strong>: consumer reach + open source (Llama, MTIA chips)</li>
              <li><strong>AWS</strong>: infra-first with custom silicon (Trainium) to reduce NVIDIA dependency</li>
              <li><strong>Microsoft</strong>: breadth across stack (Azure, OpenAI partnership, Phi, Copilot)</li>
              <li><strong>NVIDIA</strong>: ‚Äúpicks &amp; shovels‚Äù provider dominating accelerators &amp; CUDA ecosystem</li>
            </ul>

            <h2>3) Why NVIDIA captures the most value (for now)</h2>
            <p>
              GenAI stack economics are not evenly distributed. Compute dominates the recurring costs, and NVIDIA sits at the
              heart of it. While cloud hyperscalers (i.e., AWS, Azure, GCP) and model developers (i.e., OpenAI, Antropic, Meta,
              etc.) battle for adoption and differentiation, NVIDIA‚Äôs role as the supplier of GenAI gold rush (akin to ‚Äúpicks &amp
              shovels‚Äù) allows it to profit from every stage of the boom - regardless which applications or models win.
            </p>
            <ul>
              <li><strong>Market dominance</strong>: NVIDIA controls over 80% of GPUs in AI training/deployment and powers
                more than 75% of world‚Äôs TOP500 supercomputers; sole supplier of cutting edge accelerators (e.g., H100s, B200s,
                GB200s) for most enterprise-scale AI workloads
              </li>
              <li><strong>Financial performance</strong>: FY25 revenue ~$131B (+114% YoY), ~88% from compute and networking; strong
                pricing power and demand elasticity desire high ASPs
              </li>
              <li><strong>Unmatched margins</strong>: State-of-the-art accelerators yield outsized gross margins due to technological lead
                and lack of substitutes; margins supported by multi-quarter lead times for flagship GPUs
              </li>
              <li><strong>Ecosystem and switching</strong>: Proprietary CUDA software stack entrenches developers - switching requires
                significant codebase overhaul; developer ecosystem locks hyperscalers and enterprises into NVIDIA compatible workflows
              </li>
            </ul>
            <p>
              While NVIDIA‚Äôs current position is dominant, sustainability is not guaranteed:
            </p>
              <ul>
                <li>
                  <strong>Model efficiency gains</strong>: in the future incremental capability gains may not require proportional
                  increase in GPU compute; new optimization techniques could reduce FLOPs per inference
                </li>
                <li>
                  <strong>Custom silicon competition</strong>: hyperscalers and chip focused start-ups (e.g., Samba Nova) are investing
                  capital to reduce NVIDIA dependency and capture cost efficiency
                </li>
                <li>
                  <strong>Data center cyclicality</strong>: : hyperscalers may pause capex cycles once initial capacity is filled; demand
                  partly driven by catch-up infra build and may normalize post 2026
                </li>
                <li>
                  <strong>Regulatory risks</strong>: export controls (e.g., China) and supply chain constraints
                </li>
              </ul>

            <p>
              NVIDIA controls the scarcest and most non-substitutable layer - compute accelerators. As the foundational model gains
              plateau and app margins tighten, its role in powering inference with increased demand (i.e., reasoning models,
              more workloads) ensures sustained profitability. Hyperscalers (AWS, GCP, Azure, OCI) are deploying GB200s globally,
              signaling sustained medium-term growth. Rising cash reserves enable investment in next-gen GPUs (e.g., Blackwell
              architecture), manufacturing capacity, and vertical expansion via DGX Cloud - cementing NVIDIA‚Äôs lead in silicon
              and boosting profit capture across the stack.
            </p>

            <h2>4) Blurring boundaries across layers</h2>
            <p>
              Unlike the PC/Cloud eras, GenAI players actively cross layers‚Äîchipmakers launch cloud services, clouds launch models,
              and model labs ship apps. The motives: margin protection, user lock-in, speed, and ecosystem control (e.g., CUDA,
              agent protocols).
            </p>

            <h2>5) How winners will differentiate</h2>
            <ul>
              <li><strong>Proprietary assets</strong>: specialized hardware, data, and software moats</li>
              <li><strong>Integration depth</strong>: embed into daily workflows to raise switching costs (e.g., Copilot suite)</li>
              <li><strong>Adaptive expansion</strong>: move quickly as stack boundaries shift</li>
            </ul>

            <hr />
            <!-- <p><em>Originally developed from my internal write-up ‚ÄúGenAI stack v5.‚Äù</em></p> -->
            <p><a class="text-link" href="../index.html#blog">‚Üê Back to all posts</a></p>
          </article>
        </div>
      </section>
    </main>

    <footer class="site-footer" id="contact">
      <div class="container footer-content">
        <div>
          <h2>Let's stay in touch</h2>
          <p>Reach out for collaborations, thought partnership, or a friendly banter.</p>
        </div>
        <div class="footer-links">
          <a href="mailto:aaryanshah661@gmail.com">E-mail</a>
          <a href="https://www.linkedin.com/in/shahaaryan" target="_blank" rel="noopener noreferrer">LinkedIn</a>
          <a href="https://github.com/ashah661" target="_blank" rel="noopener noreferrer">GitHub</a>
        </div>
      </div>
      <p class="footer-copy">¬© <span id="current-year"></span> Aaryan Shah. All rights reserved.</p>
    </footer>

    <script>
      document.getElementById("current-year").textContent = new Date().getFullYear();
    </script>
    <script>
      (function () {
        const saved = localStorage.getItem('theme');
        if (saved === 'light') document.documentElement.setAttribute('data-theme', 'light');
      })();
      
      document.querySelector('.theme-toggle').addEventListener('click', () => {
        const html = document.documentElement;
        const isLight = html.getAttribute('data-theme') === 'light';
        if (isLight) {
          html.removeAttribute('data-theme');
          localStorage.removeItem('theme');
        } else {
          html.setAttribute('data-theme', 'light');
          localStorage.setItem('theme', 'light');
        }
      });
    </script>
  </body class="blog-post">
</html>
